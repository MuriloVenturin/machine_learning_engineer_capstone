{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Udacity - Machine Learning Engineer Nanodegree Program\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Capstone Project\n",
    "Murilo Venturin  \n",
    "March 10th, 2020\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Proposal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Domain Background"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Breast cancer is a major cause of mortality in women worldwide. Thus, considering the statistics are not promising and the fact that the effectiveness of therapies used against breast cancer is limited. Most cases are diagnosed in late stages. It is emphasized that the chances of a cure are increased the sooner the disease is diagnosed.\n",
    "\n",
    "The project's proposal is to build a model capable of classifying breast cancer between benign and malignant based on tumor data, such as radius, texture, perimeter, among other features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3. Problem Statement\n",
    "\n",
    "Conventional methods of monitoring and diagnosing\n",
    "diseases depend on the detection of the presence of particular signs\n",
    "characteristics by a human observer. Due to the large number of patients in intensive care units and the need for continuous observation, this work ends up taking a lot of time from health professionals.\n",
    "\n",
    "An automated diagnostic approach can solve this problem. A machine learning model can transform this diagnosis based on qualitative criterion faster and more objective, occupying less time of professionals and analyzing quantitative criterion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4. Datasets and Inputs\n",
    "The dataset is from the University of California, Irvine, School of Information and Computer Sciences, and can be accessed through the link:\n",
    "\n",
    "https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+%28Diagnostic%29\n",
    "\n",
    "and on kaggle:\n",
    "\n",
    "https://www.kaggle.com/uciml/breast-cancer-wisconsin-data\n",
    "\n",
    "   The fine needle aspiration data set for breast lesions contains 569 samples of fine needle aspirate from breast nodules (FNAB), including 212 positive samples (malignancy) and 357 negative (benign) samples. All the samples were confirmed by biopsy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each sample contains the following information:\n",
    "\n",
    "- 1) ID number\n",
    "- 2) Diagnosis (M = malignant, B = benign)\n",
    "\n",
    "Ten real-valued features are computed for each cell nucleus:\n",
    "\n",
    "- a) radius (mean of distances from center to points on the perimeter)\n",
    "- b) texture (standard deviation of gray-scale values)\n",
    "- c) perimeter\n",
    "- d) area\n",
    "- e) smoothness (local variation in radius lengths)\n",
    "- f) compactness (perimeter ^ 2 / area - 1.0)\n",
    "- g) concavity (severity of concave portions of the contour)\n",
    "- h) concave points (number of concave portions of the contour)\n",
    "- i) symmetry\n",
    "- j) fractal dimension (\"coastline approximation\" - 1)\n",
    "\n",
    "The mean, standard error and \"worst\" or largest (mean of the three\n",
    "largest values) of these features were computed for each image,\n",
    "resulting in 30 features. For instance, field 3 is Mean Radius, field\n",
    "13 is Radius SE, field 23 is Worst Radius."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.4.1. Data Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset consists of a single file called data.csv, which contains the following columns:\n",
    "- id                           \n",
    "- diagnosis                    \n",
    "- radius_mean                  \n",
    "- texture_mean                 \n",
    "- perimeter_mean               \n",
    "- area_mean                    \n",
    "- smoothness_mean              \n",
    "- compactness_mean             \n",
    "- concavity_mean               \n",
    "- concave points_mean          \n",
    "- symmetry_mean                \n",
    "- fractal_dimension_mean       \n",
    "- radius_se                    \n",
    "- texture_se                   \n",
    "- perimeter_se                 \n",
    "- area_se                      \n",
    "- smoothness_se                \n",
    "- compactness_se               \n",
    "- concavity_se                 \n",
    "- concave points_se            \n",
    "- symmetry_se                  \n",
    "- fractal_dimension_se         \n",
    "- radius_worst                 \n",
    "- texture_worst                \n",
    "- perimeter_worst              \n",
    "- area_worst                   \n",
    "- smoothness_worst             \n",
    "- compactness_worst            \n",
    "- concavity_worst              \n",
    "- concave points_worst         \n",
    "- symmetry_worst              \n",
    "- fractal_dimension_worst   \n",
    "\n",
    "<p style='text-align: center;'>\n",
    "    <img src=\"../images/img.png\" alt=\"Accuracy Formula\">\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before training the model, it will be necessary to perform a pre-processing of the data, which includes removing the \"id\" column as it is not a relevant feature, checking for missing data and finally normalizing the data between the values of 0.0 and 1.0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5. Solution Statement\n",
    "\n",
    "Before building the classifier model, python libraries such as numpy, pandas, matplotlib and seaborn will be used to visualize and clean the data. SKlearn mathematical techniques such as MinMaxScaler will be used in the data pre-processing step, to make the data less sparse for the model.\n",
    "\n",
    "The k-fold cross-validation method with k = 5 will be used to verify that the results of the models are consistent.\n",
    "\n",
    "Subsequently, models will be built using SKlearn supervised estimators, such as:\n",
    "- SVM\n",
    "- Gradient Boosting Classifier\n",
    "- Stochastic Gradient Descent\n",
    "- Decision tree\n",
    "- Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.6. Benchmark Model\n",
    "\n",
    "the results of each model will be compared to define the best solution.\n",
    "It is expected to achieve an accuracy greater than 95% in the average K-fold training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.7. Evaluation Metrics\n",
    "\n",
    "To validate the models, the following metrics will be used:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.7.1. Confusion Matrix\n",
    "The Confusion matrix is one of the most intuitive and easiest metrics used for finding the correctness. The Confusion matrix in itself is not a performance measure as such, but almost all of the performance metrics are based on Confusion Matrix and the numbers inside it.\n",
    "\n",
    "- True Positives (TP): True positives are the cases when the actual class of the data point was 1(True) and the predicted is also 1(True)\n",
    "\n",
    "- True Negatives (TN): True negatives are the cases when the actual class of the data point was 0(False) and the predicted is also 0(False)\n",
    "\n",
    "- False Positives (FP): False positives are the cases when the actual class of the data point was 0(False) and the predicted is 1(True). False is because the model has predicted incorrectly and positive because the class predicted was a positive one. (1)\n",
    "\n",
    "- False Negatives (FN): False negatives are the cases when the actual class of the data point was 1(True) and the predicted is 0(False). False is because the model has predicted incorrectly and negative because the class predicted was a negative one. (0)\n",
    "\n",
    "<p style='text-align: center;'>\n",
    "    <img src=\"../images/matrix.png\" alt=\"Accuracy Formula\">\n",
    "</p>\n",
    "\n",
    "#### 1.7.2. Accuracy\n",
    "Accuracy in classification problems is the number of correct predictions made by the model over all kinds predictions made.\n",
    "\n",
    "<p style='text-align: center;'>\n",
    "    <img src=\"../images/Accuracy.png\" alt=\"Accuracy Formula\" width=\"35%\">\n",
    "</p>\n",
    "\n",
    "#### 1.7.3. Precision\n",
    "\n",
    "Letâ€™s use the same confusion matrix as the one we used before for our cancer detection example.\n",
    "Precision is a measure that tells us what proportion of patients that we diagnosed as having malignant cancer, actually had  malignant cancer. The predicted positives (People predicted as malignant cancerous are TP and FP) and the people actually having a malignant cancer are TP.\n",
    "\n",
    "<p style='text-align: center;'>\n",
    "    <img src=\"../images/precision.png\" alt=\"Accuracy Formula\" width=\"30%\">\n",
    "</p>\n",
    "\n",
    "#### 1.7.4. Recall\n",
    "\n",
    "Recall is a measure that tells us what proportion of patients that actually had malignant cancer was diagnosed by the algorithm as having malignant cancer. The actual positives (People having malignant cancer are TP and FN) and the people diagnosed by the model having a malignant cancer are TP. \n",
    "\n",
    "<p style='text-align: center;'>\n",
    "    <img src=\"../images/recalll.png\" alt=\"Accuracy Formula\" width=\"30%\">\n",
    "</p>\n",
    "\n",
    "#### 1.7.5. F1 Score\n",
    "\n",
    "The F1 score combines recall with precision so that they bring in a single number.\n",
    "\n",
    "<p style='text-align: center;'>\n",
    "    <img src=\"../images/f1.png\" alt=\"Accuracy Formula\" width=\"30%\">\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.8. Project Design\n",
    "\n",
    "#### 1.8.1. Data visualization\n",
    "* View dataset graphs to understand it better\n",
    "\n",
    "#### 1.8.1. Data preprocessing\n",
    "* Check for missing data.\n",
    "* Transform non-numeric fields into numeric ones, if necessary.\n",
    "* Normalize the data using MinMaxNormalization.\n",
    "\n",
    "#### 1.8.1. Model Building\n",
    "* Train different types of models, using K-fold in all.\n",
    "* Check which was the best model using the metrics defined above\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
